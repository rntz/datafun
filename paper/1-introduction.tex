\section{Introduction}

The phrase ``declarative programming'' is as popular as it is ambiguous, with
seemingly hundreds of disparate senses in which it is used. However, two of
those usages stand out for popularity: both \emph{functional} and \emph{logic}
programming languages are generally deemed declarative languages. Despite this
common epithet, the logic and functional programming traditions have largely
evolved independently of one another (with a few honorable exceptions such as
Mercury~\cite{mercury}, Curry~\cite{curry} and Kanren~\cite{kanren}). This could
be seen as an occasion for sorrow, but we prefer to view it as an opportunity:
as functional language designers, we can look to logic languages to discover new
ideas to steal.

A Prolog program can be understood as a collection of logical axioms formulated
as Horn clauses (i.e., first-order formulas of the form $\forall \vec{x}.\;P_1
\land \ldots \land P_n \to Q$, where $P_i$ and $Q$ are atomic formulas).
Execution of a Prolog program can be understood as running a proof search
algorithm on these clauses to figure out whether a particular formula is
derivable or not.

In other words, functional and logic programming languages embody the
Curry-Howard correspondence in two different ways. In a functional language,
types are propositions, terms are proofs, and program evaluation corresponds to
proof normalization. On the other hand, for logic programming languages,
\emph{terms} are propositions, and program evaluation corresponds to \emph{proof
  search}.

Since proof search is in general undecidable, designers of logic programming
languages must be careful both about the kinds of formulas they admit as
programs, and about the proof search algorithm they implement. Prolog offers a
very expressive language --- full Horn clauses --- and so faces an undecidable
proof search problem. Therefore, Prolog specifies its proof search strategy:
depth-first goal-directed search. This lets Prolog programmers reason about the
behaviour of their programs; however, it also means many logically natural
programs fail to terminate. Notoriously, transitive closure calculations are
much less elegant in Prolog than one might hope, since their most natural
specification is best computed with a breadth-first proof search strategy.

\todo{Don't we mean ``a bottom-up/forward-chaining proof search strategy''? Does
  breadth-first backward-chaining search work for transitive closure?}

This view of Prolog suggests considering other possible design choices, such as
restricting the logical language so as to make proof search decidable. One of
the oldest such variants is Datalog~\cite{datalog}, which can be seen as a
subset of Prolog satisfying three restrictions on the clauses defining a
program:

\begin{enumerate}
\item Terms occurring in predicates are forbidden from being composites: they
  can only be ground terms, or variables. This restriction ensures that
  deduction will never introduce new terms that do not occur in the source of
  the program.

\item Variables occurring in the head of a clause (i.e., the consequent of a
  Horn clause) must also occur (positively) in the body (i.e., the premises of a
  Horn clause).

\item No predicate can be negated unless it has already been fully defined. This
  is sometimes called ``stratified negation''.
\end{enumerate}

These drastic restrictions make Datalog Turing-incomplete -- all queries are
decidable. As functional programmers are well aware, though, there is often
power in restraint: for example, in a total functional language, the compiler is
free to switch between strict and lazy evaluation as it deems fit. Similarly, in
Datalog decidability means that implementations are free to use forwards
chaining, and so can easily support queries (like reachability and transitive
closure) which are difficult to implement in ordinary Prolog.

%% PREVIOUS PARAGRAPH:
%
% Thanks to this decidability, Datalog implementations are free to
% tailor their proof search strategy to the program being executed.
% Consequently Datalog programs can be both concise and efficient. For
% example, \citet{whaley-lam} implemented pointer analysis algorithms in
% Datalog, and found that they could reduce their analyses from
% \emph{thousands} to \emph{tens} of lines of code while retaining
% competitive performance.

Over the last decade or so, this freedom has been put to very good use, with
Datalog appearing at the heart of a a wild variety of applications in both
research and industry. For example, Whaley and Lam \cite{whaley-lam,whaley-phd}
implemented pointer analysis algorithms in Datalog, and found that they could
reduce the size of their analyses from thousands of lines of C code to
\emph{tens} of lines of Datalog code, while still retaining competitive
performance. Semmle has developed the .QL
language~\cite{semmlecode,ql-inference} based on Datalog for analysing source
code (which was used to analyze the code for NASA's Curiosity Mars rover), and
LogicBlox has developed the LogiQL~\cite{logicblox} language for business
analytics. The Boom project at Berkeley has developed the Bloom language for
distributed programming~\cite{bloom}, and the Datomic cloud
database~\cite{datomic} uses Datalog (embedded in Clojure) as its query
language. Microsoft's SecPAL language~\cite{secpal} uses Datalog as the
foundation of its decentralised authorization specification language.

In all of these cases, the use of Datalog permits giving specifications and
implementations which are dramatically shorter and clearer than alternatives
implemented in more conventional languages. However, while all of these
applications are built on a foundation of Datalog, they all also extend it
significantly. For example, it is impossible even to implement arithmetic in
Datalog, since adding 2 and 3 produces 5, which is a new term not equal to
either 2 or 3! As a result, even though Datalog has a very clean semantics, its
metatheory needs to be re-established once again for each application-specific
extension to it.

As a result, it would be very desirable to understand what makes Datalog tick,
so that we can embed into a more expressive language \emph{without} sacrificing
the properties that make it so powerful within its domain. In this way,
extensions can become ``a simple matter of programming'', without having to do a
custom redesign of the language for each application.

In this paper, we present Datafun, a typed functional language which permits
programming in the style of Datalog, while still supporting the full power of
higher-order functional programming.

\paragraph{Contributions}
\begin{itemize}
\item We describe Datafun, a typed language capturing the expressive power of
  Datalog and extending it to support higher-order functional programming.
  Datafun's key feature is to \emph{track monotonicity with types}. This permits
  us to use typing to analyze fixed point computations in a way ensuring their
  termination.

\item We present examples illustrating the expressive power of Datafun,
  including relational-algebra-style operations, transitive closure, CYK
  parsing, and dataflow analysis. Some of these examples are familiar from
  Datalog, but many of them go well beyond what can be expressed in it,
  illustrating the benefits of our analysis.

\item We identify the semantic structures underpinning Datalog, and use this to
  give a denotational semantics for Datafun in terms of a pair of adjunctions
  between \cSet{}, \cPoset{}, \cSL{}.

\item We have a prototype implementation of Datafun in Racket. \todo{(CITE)}
\end{itemize}

%% Contributions (as summarized by Michael):
% - Datafun, like Datalog but functional
% - examples, incl. both datalog examples & things datalog canâ€™t do
% - key ingredient is monotonicity; ``found'' semantics by analyzing
%   datalog: two adjunctions, three categories
% - prototype implementation

%% Contributions (as written by Neel):

% - We describe Datafun, a type theory for a language capturing the expressive
%   power of Datalog and extends it to both relax the constructor term
%   restriction and to support higher-order functional programming.

% - We give a variety of examples that illustrate the expressive power of
%   Datafun, such as CYK parsing, dataflow analysis, and transitive closure on
%   graphs, etc. Many of these examples are traditional examples of Datalog,
%   but we are also able to support things like first-class relations (eg,
%   generic transitive closure) and higher-order functions (example using
%   monotonicity and HO?). (doing a fix-point code analysis / parsing something
%   & dispatching on result?)

% - We identify the semantic structures underpinning Datalog, and use this to
%   give a denotational semantics for Datafun in terms of a pair of adjunctions
%   between Set, Poset, and the category of semilattices with finitary joins.

% - We have a prototype implementation of Datafun in Racket.

% Local Variables:
% TeX-master: "datafun"
% End:
