\section{From Semi\naive{} Evaluation to the Incremental \boldfn-Calculus}
\label{sec:seminaive-and-ilc}

Consider the following Datalog fragment:\footnote{This example and explanation
  of semi\naive\ evaluation is borrowed almost entirely from
  \citet{DBLP:conf/esop/Alvarez-Picallo19}.}

\begin{align*}
  \name{path}(x,y) &\gets \name{edge}(x,y)
  &
  \name{path}(x,z) &\gets \name{edge}(x,y) \wedge \name{path}(y,z)
\end{align*}


\noindent
The denotation of \name{path} is the least fixed point of the rules defining
it.
% mention Kleene fixed point theorem?
We can compute this by repeatedly applying these rules until the collection
of known paths (initially empty) stops growing.
%
For example, if the \name{edge} relation is \{(1,\,2), (2,\,3), (3,\,4)\}, we
get the following evaluation trace:

%% TODO: make sure there's enough vertical space around this.
\nopagebreak[2]
\begin{center}
  \setlength\tabcolsep{1em}
  \begin{tabular}{@{}rll@{}}
    Step
    & Previously known paths
    & Paths deduced at this step
    \\\midrule
    0
    & none
    & (1,\,2) (2,\,3) (3,\,4)
    \\
    1
    & (1,\,2) (2,\,3) (3,\,4)
    & (1,\,2) (2,\,3) (3,\,4) (1,\,3) (2,\,4)
    \\
    2
    & (1,\,2) (2,\,3) (3,\,4) (1,\,3) (2,\,4)
    & (1,\,2) (2,\,3) (3,\,4) (1,\,3) (2,\,4) (1,\,4)
    \\
    3
    & (1,\,2) (2,\,3) (3,\,4) (1,\,3) (2,\,4) (1,\,4)
    & as above
  \end{tabular}
\end{center}

\noindent We have now reached the desired fixed point. However, this process is
quite wasteful: we deduced the path (1,\,2) at \emph{every} iteration; ideally
we'd only deduce it once. On a chain of $n$ edges, we deduce $\Theta(n^3)$
facts, even though there are only $\Theta(n^2)$ paths!

The standard improvement to this strategy is
\emph{semi\naive\ evaluation}~\cite{seminaive}, which transforms recursive rules
into explicitly iterative time-indexed rules of two kinds: \emph{derivative}
rules, to compute the new facts at each iteration; and \emph{accumulator} rules,
to collect these facts into a final result.
%
In this case, the derivative rule is simple: we discover new paths at iteration
$i+1$ by appending edges to paths which were new at iteration $i$:

\begin{align*}
  \name{dpath}_0(x,y) &\gets \name{edge}(x,y)
  \\
  \name{dpath}_{i+1}(x,z) &\gets \name{edge}(x,y) \wedge \name{dpath}_i(y,z)
  \\
  \name{path}_{i+1}(x,y) &\gets \name{path}_i(x,y) \vee \name{dpath}_i(x,y)
\end{align*}

\noindent This yields the execution trace:

\begin{center}
  \setlength\tabcolsep{1em}
  \begin{tabular}{@{}rll@{}}
    Step & $\name{path}_i$ & $\name{dpath}_i$
    \\\midrule
    0 & empty & (1,\,2) (2,\,3) (3,\,4)
    \\
    1 & (1,\,2) (2,\,3) (3,\,4) & (1,\,3) (2,\,4)
    \\
    2 & (1,\,2) (2,\,3) (3,\,4) (1,\,3) (2,\,4) & (1,\,4)
    \\
    3 & (1,\,2) (2,\,3) (3,\,4) (1,\,3) (2,\,4) (1,\,4) & empty
  \end{tabular}
\end{center}

%% TODO: email Alvarez-Picallo, Michael P-J, etc; they say "a quadratic
%% computation into a linear one" but AFAICT this is not so! Unless the claim is
%% that the naive version is quadratic in the _output_?!
%%
%% Perhaps we should say, "--- our computation is now linear in the size of its
%% output". But is this really justified?
\noindent
This is much better --- we have turned a cubic computation into a quadratic one!


\subsection{Semi\naive\ evaluation as incremental computation}

Now let's move from Datalog to Datafun. The transitive closure of \name{edge} is
the fixed point of the monotone function \name{step} defined by:

\nopagebreak[2]
\[
\name{step} \<\name{path} = \name{edge} \cup
\setfor{(x,z)}{(x,y) \in \name{edge}, (y,z) \in \name{path}}
\]

\noindent
The \naive\ way to compute \name{step}'s fixed point is to iterate it: start
with \(\name{path}_0 = \emptyset\) and compute \(\name{path}_{i+1} =
\name{step}\<\name{path}_i\) for increasing $i$ until \(\name{path}_i =
\name{path}_{i+1}\).
%
But since $\name{path}_i \subseteq \name{step}\<\name{path}_i$, each iteration
re-computes every path found by the previous iteration.
%
Following Datalog, we'd prefer to compute only the \emph{change} between
iterations.
%
So consider $\name{step}'$ defined by:

\nopagebreak[2]
\[
\name{step}' \<\name{dpath} =
\setfor{(x,z)}{(x,y) \in \name{edge}, (y,z) \in \name{dpath}}
\]

\noindent
Observe that $\name{step} \<(\name{path} \cup \name{dpath}) =
\name{step}\<\name{path} \cup \name{step}'\<\name{dpath}$.
%
That is, $\name{step}'$ tells us how \name{step} changes as its input grows.
%
Using this property, we can directly compute the changes $\name{dpath}_i$
between our iterations $\name{path}_i$:

%% \begin{align*}
%%   \name{dpath}_0 &= \name{step}\<\emptyset
%%   & \name{dpath}_{i+1} &= \name{step}'\<\name{dpath}_i
%%   & \name{path}_{i+1} &= \name{path}_i \cup \name{dpath}_i
%% \end{align*}

%% \[\def\arraystretch{1.2}
%% \begin{array}{rclcl}
%%   \name{dpath}_0 &=& \name{step}\<\emptyset
%%   &=& \name{edge}
%%   \\
%%   \name{dpath}_{i+1} &=& \name{step}'\<\name{dpath}_i
%%   &=& \setfor{(x,z)}{(x,y) \in \name{edge}, (y,z) \in \name{dpath}_i}
%%   \\
%%   \name{path}_{i+1} &=& \name{path}_i \cup \name{dpath}_i
%% \end{array}\]

\begin{align*}
  \name{dpath}_0
  &= \name{step}\<\emptyset
  = \name{edge}
  \\
  \name{dpath}_{i+1}
  &= \name{step}'\<\name{dpath}_i
  = \setfor{(x,z)}{(x,y) \in \name{edge}, (y,z) \in \name{dpath}_i}
  \\
  \name{path}_{i+1}
  &= \name{path}_i \cup \name{dpath}_i
\end{align*}

\noindent These exactly mirror the derivative and accumulator rules for
\(\name{path}_i\) and \(\name{dpath}_i\) we gave earlier.
%
\todo{Explain how this lets us compute $\name{path}_i$ more
  efficiently and wait until it quiesces as before.}

The problem of semi\naive\ evaluation for Datafun, then, reduces to the problem
of finding functions like $\name{step}'$, which compute the change in a
function's output given a change to its input.
%
This is a problem of \emph{incremental computation}, and since Datafun is a
functional language, we turn to the
\emph{incremental \fn-calculus}~\citep{incremental}.


\subsection{The incremental \boldfn-calculus}
\label{sec:seminaive-via-incremental}

In this section we explain the incremental \fn-calculus as we have applied it to
Datafun; we discuss our differences from its formulation in
\citeauthor{incremental} in \cref{sec:differences-from-incremental}.

\todo{Explain:
  \begin{itemize}
  \item $\D(A \to B) = \iso A \to \D A \to \D B$. In particular, (a) why not
    just $\iso A \to \D B$; and (b) why the \iso?
  \item Function derivatives are zero-changes.
  \item Since we're tracking changes during fixed point iteration, and these
    increase monotonically, we only allow increasing changes. So $\iso A$
    (discussed in \cref{sec:datalog-and-datafun}) prevents things from changing!
  \end{itemize}
  }

%% what do we need here?

%% \todo{explain how $\name{step}'$ looks like a derivative of $\name{step}$ in the
%%   sense of \citet{incremental}.}


\subsection{Examples of semi\naive\ Datafun programs}
\XXX

In order to explain in detail how our static transformation operates and why it
is correct, however, we first need a fuller account of Datafun's type system and
semantics.
