\section{Discussion and related work}
\label{sec:related-work}

\label{sec:differences-from-incremental}

\paragraph{Nested fixed points}\label{sec:nested-fixed-points}
%
The typing rule for $\efix e$ requires $e : \iso(\fixt L \to \fixt L)$.
%
The $\phi$ translation takes advantage of this $\iso$, decorating expressions of
type $\iso A$ with their zero changes.
%
However, it also prevents an otherwise valid idiom: in a nested fixed-point
expression $\efixis{x}{\dots (\efixis{y}{e}) \dots}$, the inner fixed point body $e$
cannot use the monotone variable $x$!
%
This restriction is not present in \citet{datafun}; its addition brings Datafun
closer to Datalog, whose syntax cannot express this sort of nested fixed point.

We suspect it is possible to lift this restriction without losing
semi\naive\ evaluation, by decorating \emph{all} expressions and variables (not
just discrete ones) with zero changes.
%
However, this also invalidates $\delta(\efix f) = \bot$: now that $f$ can
change, so can $\efix f$.
% Argh, using \delta here is technically wrong. because \delta should be
% incrementalizing \phi. this is more like \Deriv. But if we use \Deriv people
% will be confused, and this is a very technical point.
Luckily, there is a simple and correct solution: $\delta(\efix f) =
\efix \ebox{\delta f \<\ebox{\efix f}}$~\cite{delta-fix}.
%
However, to compute this new fixed point semi\naive{}ly, we need a \emph{second
  derivative}: the zero change to $\delta f \<\ebox{\efix f}$. Indeed, for a
program with fixed points nested $n$ deep, we need $n$\textsuperscript{th}
derivatives. We leave this to future work.

%% Can't we just have \delta produce two expressions: the derivative, and the
%% zero change to the derivative?


\paragraph{Self-maintainability}

In the incremental $\fn$-calculus, a function $f$ is called
\emph{self-maintainable} if its derivative $f'$ depends only upon the change
$\dx$ to the argument and not upon the base point $x$. This is a crucial
property, because it means we can compute the change in the function's result
without re-computing the original input, which might be expensive. So it's
reasonable to ask whether self-maintainability (or rather, its absence) is ever
an issue for semi\naive\ Datafun. We suspect (but have no proof) that because of
the limited way semi\naive\ evaluation uses incremental computation, it usually
isn't. For example, consider a variant definition of transitive closure, as the
fixed point of \(f = \fnof{\name{path}} \name{edge} \cup (\name{path} \relcomp
\name{path})\). This is not self-maintainable; its derivative is:

\begin{code}
  f' \<\name{path} \<\name{dpath} =
  (\name{path} \relcomp \name{dpath})
  \vee (\name{dpath} \relcomp \name{path})
  \vee (\name{dpath} \relcomp \name{dpath})
\end{code}

\noindent
However, this is not a problem when computing its fixed point semi\naive{}ly,
because both \name{path} and \name{dpath} are available from the previous
iteration. Thus non-self-maintainable fixed points do not appear to be forced
into doing extensive recomputation.



\paragraph{Related work}

The incremental lambda calculus was introduced by \citet{incremental},
as a static program transformation which associated a type of
\emph{changes} to each base type, along with operations to update a
value based on a change.  Then, a program transformation on the
simply-typed lambda calculus with base types and functions was
defined, which rewrote lambda terms into incremental functions which
propagated changes as needed to reduce recomputation. The fundamental
idea of the incremental function type taking two arguments (a base
point and a change) is one we have built on, though we have extended
the transformation to support many more types like sums, sets,
modalities, and fixed points.
%
Subsequently, \citet{DBLP:conf/esop/GiarrussoRS19} extended this work
to support the \emph{untyped} lambda calculus, additionally also
extending the incremental transform to support additional
\emph{caching}. In this work, the overall correctness of change
propagation was proven using a step-indexed logical relation, which
defined which changes were valid in a fashion very similar to our own.

The motivating example of this line of work was to optimize bulk collection
operations. However, all of the intuitions were phrased in terms of calculus ---
a change structure can be thought of as a space paired with its tangent space, a
zero change on functions is a derivative, and so on. However, the idea of a
derivative as a linear approximation is taken most seriously in the work on the
differential lambda calculus~\cite{dlc}. These calculi have the beautiful
property that the \emph{syntactic} linearity in the lambda calculus corresponds
to the \emph{semantic} notion of linear transformation.

Unfortunately, the intuition of a derivative has its limits. A function's
derivative is \emph{unique}, a property which models of differential lambda
calculi have gone to considerable length to
enforce~\cite{differential-categories}. This is problematic from the point of
view of semi\naive\ evaluation, since we make use of the freedom to
overapproximate.
%
In \cref{sec:semilattice-delta-phi}, we followed common practice from Datalog
and took the derivative $\delta(e \vee f)$ to be $\delta(e) \vee \delta(f)$,
which may overapproximate the change to $e \vee f$.
%
This spares us from having to do certain recomputations to construct set
differences; it is not clear to what extent semi\naive\ evaluation's practical
utility depends on this approximation.

\citet{DBLP:conf/esop/Alvarez-Picallo19} offer an alternative
formulation of change structures, by requiring changes to form a
monoid, and representing the change itself with a monoid action. They
use change actions to prove the correctness of semi\naive\ evaluation
for Datalog, and express the hope that it could apply to Datafun.
Unfortunately, it does not seem to -- the natural notion of function
change in their setting is pointwise, which does not seem to lead to
the derivatives we want in the examples we considered.

Overall, there seems to be a lot of freedom in the design space for
incremental calculi, and the tradeoffs different choices are making
remain unclear. Much further investigation is warranted!


% \paragraph{Semantics of Seminaive Evaluation}

% \paragraph{Flix and Higher-Order Datalog}



