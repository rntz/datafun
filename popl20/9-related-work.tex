\section{Discussion and Related Work}
\label{sec:related-work}

\label{sec:differences-from-incremental}

\paragraph{Nested fixed points}
%
The typing rule for $\efix e$ requires $e : \iso(\fixt L \to \fixt L)$.
%
The $\phi$ translation takes advantage of this $\iso$, decorating expressions of
type $\iso A$ with their zero-changes.
%
However, it also prevents an otherwise valid idiom: in a nested fixed-point
expression $\efixis x \dots (\efixis y e) \dots$, the inner fixed point body $e$
cannot use the monotone variable $x$!
%
This restriction is not present in \citet{datafun}; its addition brings Datafun
closer to Datalog, whose syntax cannot express this sort of nested fixed point.

We suspect it is possible to lift this restriction without losing
semi\naive\ evaluation, by decorating \emph{all} expressions and variables (not
just discrete ones) with zero-changes.
%
However, this also invalidates $\delta(\efix f) = \bot$: now that $f$ can
change, so can $\efix f$.
% TODO: Argh, using \delta here is technically wrong. because \delta
% should be incrementalizing \phi. this is more like \Deriv. But if we
% use \Deriv people will be confused, and this is a very technical
% point.
Luckily, there is a simple and correct solution: $\delta(\efix f) =
\efix \ebox{\delta f \<\ebox{\efix f}}$~\cite{delta-fix}.
%
However, to compute this new fixed point semi\naive{}ly, we need a \emph{second
  derivative}: the zero-change to $\delta f \<\ebox{\efix f}$. Indeed, for a
program with fixed points nested $n$ deep, we need $n$\textsuperscript{th}
derivatives. We leave this to future work.

%% Can't we just have \delta produce two expressions: the derivative, and the
%% zero-change to the derivative?

\paragraph{Related Work}
The incremental lambda calculus was introduced by \citet{incremental},
as a static program transformation which associated a type of
\emph{changes} to each base type, along with operations to update a
value based on a change.  Then, a program transformation on the
simply-typed lambda calculus with base types and functions was
defined, which rewrote lambda terms into incremental functions which
propagated changes as needed to reduce recomputation. The fundamental
idea of the incremental function type taking two arguments (a base
point and a change) is one we have built on, though we have extended
the transformation to support many more types like sums, sets,
modalities, and fixed points.
%
Subsequently, \citet{DBLP:conf/esop/GiarrussoRS19} extended this work
to support the \emph{untyped} lambda calculus, additionally also
extending the incremental transform to support additional
\emph{caching}. In this work, the overall correctness of change
propagation was proven using a step-indexed logical relation, which
defined which changes were valid in a fashion very similar to our own.

The motivating examples of this line of work was to optimize bulk
collection operations, and benchmarks showing asymptotic performance
improvements were demonstrated. However, all of the intuitions were
phrased in terms of calculus -- a change structure can be thought of
as a space paired with its tangent space, a zero change on functions
is a derivative, and so on. The idea of a derivative as a linear
approximation is taken most seriously in the work on
the differential lambda calculus~\cite{dlc}. These calculi have the
beautiful property that the \emph{syntactic} linearity in
the lambda calculus corresponds to the \emph{semantic} notion of
linear transformation. 

Unfortunately, the intuition of a derivative has its limits. A
function's derivative is \emph{unique}, a property which models of
differential lambda calculi have gone to considerable length to
enforce~\cite{differential-categories}. This is problematic from the
point of view of semi\naive\ evaluation, since we must have the
freedom to overapproximate. In
\cref{sec:semilattice-delta-phi}, we took the derivative
$\delta(e \vee f)$ to be $\delta(e) \vee \delta(f)$, which may
overapproximate the change to $e \vee f$. This spares us from having
to do expensive recomputations to construct set differences, and
without this freedom it is doubtful that semi\naive\ evaluation would
even be useful at all!

\citet{DBLP:conf/esop/Alvarez-Picallo19} offer an alternative
formulation of change structures, by requiring changes to form a
monoid, and representing the change itself with a monoid action. They
use change actions to prove the correctness of semi\naive\ evaluation
for Datalog, and express the hope that it could apply to Datafun.
Unfortunately, it does not seem to -- the natural notion of function
change in their setting is pointwise, which does not seem to lead to
the derivatives we want in the examples we considered.

Overall, there seems to be a lot of freedom in the design space for
incremental calculi, and the tradeoffs different choices are making
remain unclear. Much further investigation is warranted!


% \paragraph{Semantics of Seminaive Evaluation}

% \paragraph{Flix and Higher-Order Datalog}



