\section{Discussion and Related Work}
\label{sec:related-work}

\label{sec:differences-from-incremental}

\paragraph{Nested fixed points}
%
The typing rule for $\efix e$ requires $e : \iso(\fixt L \to \fixt L)$.
%
The $\phi$ translation takes advantage of this $\iso$, decorating expressions of
type $\iso A$ with their zero-changes.
%
However, it also prevents an otherwise valid idiom: in a nested fixed-point
expression $\efixis x \dots (\efixis y e) \dots$, the inner fixed point body $e$
cannot use the monotone variable $x$!
%
This restriction is not present in \citet{datafun}; its addition brings Datafun
closer to Datalog, whose syntax cannot express this sort of nested fixed point.

We suspect it is possible to lift this restriction without losing
semi\naive\ evaluation, by decorating \emph{all} expressions and variables (not
just discrete ones) with zero-changes.
%
However, this also invalidates $\delta(\efix f) = \bot$: now that $f$ can
change, so can $\efix f$.
% TODO: argh, using \delta here is technically wrong. because \delta should be
% incrementalizing \phi. this is more like \Deriv. But if we use \Deriv people
% will be confused, and this is a very technical point.
Luckily, there is a simple and correct solution: $\delta(\efix f) = \efix \ebox{\delta f \<\ebox{\efix f}}$~\cite{delta-fix}.
%
However, to compute this new fixed point semi\naive{}ly, we need a \emph{second
  derivative}: the zero-change to $\delta f \<\ebox{\efix f}$. Indeed, for a
program with fixed points nested $n$ deep, we need $n$\textsuperscript{th}
derivatives. We leave this to future work.

%% Can't we just have \delta produce two expressions: the derivative, and the
%% zero-change to the derivative?

%% \todo{Discuss possibility of allowing nested fixed points by removing the $\iso$
%%   from $\prim{fix}$'s argument. The problem here is $\delta(\efix f)$. I've
%%   previously worked out what this should be (cite that 3-page proof on my
%%   website): $\delta(\efix f) = \efix(\delta f \<(\efix f))$. But if we want to
%%   compute \emph{this} fixed point faster, we need a \emph{second derivative}. So
%%   if your program has $n$ nested fixed points, you probably need
%%   $n$\textsuperscript{th} derivatives. Future work!}

\paragraph{Related Work}
The incremental lambda calculus was introduced by \citet{incremental},
as a static program transformation which associated a type of
\emph{changes} to each base type, along with operations to update a
value based on a change.  Then, a program transformation on the
simply-typed lambda calculus with base types and functions was
defined, which rewrote lambda terms into incremental functions which
propagated changes as needed to reduce recomputation. The fundamental
idea of the incremental function type taking two arguments (a base
point and a change) is one we have built on, though we have extended
the transformation to support many more types like sums, sets,
modalities, and fixed points.

Subsequently, \citet{DBLP:conf/esop/GiarrussoRS19} extended this work
to support the \emph{untyped} lambda calculus, additionally also
extending the incremental transform to support additional
\emph{caching}. Correctness was established via a surpringly intricate
argument. First, the overall correctness of change propagation was
proven using a step-indexed logical relation, and on top of that a
simulation argument was needed to establish the correctness of
caching. This work naturally suggests looking at caching as a way
for optimizing Datafun, as an alternative to very aggressive
inlining. 

The motivating examples of this line of work was to optimize bulk
collection operations, and benchmarks showing asymptotic performance
improvements were demonstrated. However, all of the intuitions were
phrased in terms of calculus -- a change structure can be thought of
as a space paired with its tangent space, a zero change on functions
is a derivative, and so on.

The idea of a derivative as a linear approximation to a function is
taken quite seriously in the work on the differential lambda
calculus~\cite{dlc}. These calculi have the beautiful property that
the \emph{syntactic} notion of linearity in the lambda calculus
corresponds to the \emph{semantic} notion of linear
transformation. Despite their beautiful semantics, differential lambda
calculi are initially startling to traditional functional programmers:
for example, arbitrary terms of the same type can be added together,
reflecting the fact that real-valued functions can be summed. 

Unfortunately, though, the intuition of a derivative has its limits. A
function's derivative is \emph{unique}, a property which models of
differential lambda calculi have gone to considerable length to
enforce~\cite{differential-categories}. This is problematic from the
point of view of semi\naive\ evaluation, since we must have the
freedom to overapproximate. In
section~\ref{sec:semilattice-delta-phi}, we took the derivative
$\delta(e \vee f)$ to be $\delta(e) \vee \delta(f)$, which may
overapproximate the change to $e \vee f$. This spares us from having
to do expensive recomputations to construct set differences, and
without this freedom it is doubtful that semi\naive\ evaluation
would even be useful at all! 


\paragraph{Semantics of Seminaive Evaluation}

\paragraph{Flix and Higher-Order Datalog}



