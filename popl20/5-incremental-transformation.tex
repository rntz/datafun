\section{The \boldphi\ and \bolddelta\ Transformations}
\label{sec:transformations}

We use two static transformations, $\phi$ and $\delta$, defined in
\cref{fig:phi,fig:delta} respectively. Rather than dive into the gory
details immediately, we first build some intuition.

The speed-up transform $\phi e$ computes fixed points semi\naive{}ly by
replacing $\efix f$ by $\fastfix\<({f,f'})$.
%
But to find the derivative $f'$ of $f$ we'll need a second transform, called
$\delta e$.
%
Since a derivative is a zero change, can $\delta e$ simply find a zero change to
$e$?
%
Unfortunately, this is not strong enough.
%
For example, the derivative of $\fnof x e$ depends on how $e$ changes as its
free variable $x$ changes --- which is not necessarily a zero change.
%
To compute derivatives, we need to solve the general problem of computing
\emph{changes}.
%
So, modelled on the incremental \fn-calculus' $\Deriv$ \citep{incremental},
$\delta e$ will compute how $\phi e$ changes as its free variables
change.

However, to speed up $\efix e$ we don't want the change to $e$; we want its
derivative.
%
Since derivatives are zero-changes, function changes and derivatives coincide if
\emph{the function cannot change}.
%
This is why the typing rule for $\efix e$ requires that $e : \iso(\fixt L \to
\fixt L)$: the use of $\iso$ prevents $e$ from changing!
%
So the key strategy of our speed-up transformation is to {\bfseries\boldmath
  decorate expressions of type ${\iso A}$ with their zero-changes.}
%
This makes derivatives available exactly where we need them: at \prim{fix}
expressions.


\subsection{Typing \boldphi\ and \bolddelta}

\input{fig-DeltaPhi}

In order to decorate expressions with extra information, $\phi$ also needs to
decorate their types. In \cref{fig:DeltaPhi} we give a type translation $\Phi A$
capturing this.
%
In particular, if $e : \iso A$ then $\phi e$ will have type $\Phi(\iso A) =
\iso(\Phi A \x \DP A)$.
%
The idea is that evaluating $\phi e$ will produce a pair
$\eboxraw{\etuple{x,\dx}}$ where $x : \Phi A$ is the sped-up result and $\dx :
\DP A$ is a zero-change to $x$.
%
Thus, if $e : \iso(\fixt L \to \fixt L)$, then $\phi e$ will compute
$\eboxraw{\etuple{f,f'}}$, where $f'$ is the derivative of $f$.

On types other than $\iso A$, there is no information we need to add, so $\Phi$
simply distributes.
%
In particular, source programs and sped-up programs agree on the shape of
first-order data:

\begin{lemma}\label{thm:phi-eqt}
  $\Phi\eqt A = \eqt A$.
\end{lemma}
\begin{proof}
  Induct on $\eqt A$.
\end{proof}

As we'll see in \cref{sec:var-fn-app,sec:phi-delta-box}, $\phi$ and $\delta$ are
mutually recursive. To make this work, $\delta e$ must find the change to $\phi
e$ rather than $e$.
%
So if $e : A$ then $\phi e : \Phi A$ and $\delta e : \DP A$.
%
However, so far we have neglected to say what $\phi$ and $\delta$ do to typing
contexts.
%
To understand this, it's helpful to look at what $\Phi$ and $\DP$ do to
functions and to $\iso$.
%
This is because expressions denote functions of their free variables.
%
Moreover, in Datafun free variables come in two flavors, monotone and discrete, and discrete variables are semantically $\iso$-ed.

If we view expressions as functions of their free variables, $\delta e$ will
denote the \emph{derivative} of the function $\phi e$ denotes.
%
And just as the derivative of a unary function $f\<x$ has \emph{two} arguments,
$\df\<x\<\dx$, the derivative of an expression $e$ with $n$ variables $x_1,
\dots, x_n$ will have $2n$ variables: the original $x_1, \dots, x_n$ and their
changes $\dx_1, \dots, \dx_n$.%
%
\footnote{We assume throughout the paper as a matter of notational convenience
  that source programs contain no variables starting with the letter \emph{d}.}
%
However, this says nothing yet about monotonicity or discreteness.
%
To make this precise, we'll use three context transformations, named according
to the analogous type operators $\iso$, $\Phi$, and $\Delta$:
%% %
%% We define these pointwise by their action on singleton contexts (they all
%% preserve empty contexts and distribute across context union):

\begin{align*}
  \iso{(\h x A)} &= \hd x A & \iso{(\hd x A)} &= \hd x A
  \\
  \Phi(\h x A) &= \h x {\Phi A} & \Phi(\hd x A) &= \hd x {\Phi A}, \hd \dx {\DP A}
  \\
  \D(\h x A) &= \h \dx {\D A}
  & \D(\hd x A) &= \emptycx \quad\text{\small(the empty context)}
\end{align*}

%% \begin{align*}
%%   \iso{(\h x A)} &= \hd x A & \iso{(\hd x A)} &= \hd x A
%%   \\
%%   \Phi(\h x A) &= \h x {\Phi A} & \Phi(\hd x A) &= \hd x {\Phi A}, \hd \dx {\DP A}
%%   \\
%%   \D(\h x A) &= \h \dx {\D A} & \D(\hd x A) &= \emptycx\quad\text{(the empty context)}
%% \end{align*}

\noindent
%% (All three preserve empty contexts and distribute over union; e.g. $\Phi\emptycx
%% = \emptycx$ and $\Phi(\G_1,\G_2) = \Phi\G_1, \Phi\G_2$.)
(Otherwise all three operators distribute; e.g.\ $\iso\emptycx = \emptycx$ and
$\iso(\G_1,\G_2) = \iso\G_1, \iso\G_2$.)

Intuitively, $\iso\G$, $\Phi\G$, and $\D\G$ mirror the effect of
$\iso$, $\Phi$, and $\D$ on the semantics of $\G$:

\begin{align*}
  \den{\iso\G} &\cong \iso\den\G
  &
  \begin{aligned}
    \den{\Phi(\h x A)} &\cong \den{\Phi A}
    \\
    \den{\Phi(\hd x A)} &\cong \den{\Phi \iso A}
  \end{aligned}
  &&
  \begin{aligned}
    \den{\D(\h x A)} &\cong \den{\D A}
    \\
    \den{\D(\hd x A)} &\cong \den{\D \iso A}
  \end{aligned}
\end{align*}

%% \begin{align*}
%%   \multirow{2}{*}{\den{\iso \G} = \iso\den\G}
%%   &&
%%   \den{\D(\h x A)} &\cong \den{\D A}
%%   &
%%   \den{\Phi(\h x A)} &\cong \den{\Phi A}
%%   \\
%%   &&
%%   \den{\D(\hd x A)} &\cong \den{\D \iso A}
%%   &
%%   \den{\Phi(\hd x A)} &\cong \den{\Phi \iso A}
%% \end{align*}

\noindent
These defined, we can state the types of $\phi e$ and $\delta e$:

\begin{theorem}[Well-typedness]
  \label{thm:type-correct}
  If $\J e \G A$, then
  \begin{align*}
    \Jalign {\phi e} {\Phi\G} {\Phi A}\\
    \Jalign {\delta e} {\iso{\Phi\G}, \DP\G} {\DP A}
  \end{align*}
\end{theorem}

%% \begin{proof}
%%   By induction on typing derivations; see appendix.
%% \end{proof}

\noindent As expected if we view expressions as functions of their free
variables, if we pretend $\G$ is a type, these correspond to $\Phi(\G \to A)$
and $\DP(\G \to A)$ respectively:

\begin{align*}
  \Phi(\G \to A) &= \Phi\G \to \Phi A
  & \DP(\G \to A) &= \iso\Phi\G \to \DP\G \to \DP A
\end{align*}

%% TODO: can I maybe cut this bit?
\noindent
To get the hang of these context and type transformations, suppose $\J
e {\hd x A, \h y B} C$. Then \cref{thm:type-correct} tells us:

\nopagebreak[1]
\begin{align*}
  \Jalign{\phi e} {\hd x{\Phi A},\, \hd \dx {\DP A},\, \h y {\Phi B}} {\Phi C}
  \\
  \Jalign{\delta e} {\hd x{\Phi A},\, \hd\dx{\DP A},\, \hd y{\Phi B}, \h\dy{\DP B}} {\DP C}
\end{align*}

%% %% TODO: should we include this? I think the point is pretty well-made already.
%% \noindent
%% These correspond respectively to $\Phi$ and $\DP$ applied to $\iso A \to B \to
%% C$:
%%
%% \begin{align*}
%%   \Phi(\iso A \to B \to C)
%%   &= \iso (\Phi A \x \DP A) \to \Phi B \to \Phi C
%%   \\
%%   \DP(\iso A \to B \to C)
%%   &= \D(\iso (\Phi A \x \DP A) \to \Phi B \to \Phi C)\\
%%   &= \iso (\iso (\Phi A \x \DP A))
%%   \to \D(\iso (\Phi A \x \DP A))
%%   \to \D(\Phi B \to \Phi C)\\
%%   &\cong \iso (\Phi A \x \DP A)
%%   \to \tunit
%%   \to \iso\Phi B \to \DP B \to \DP C\\
%%   &\cong \iso \Phi A \to \iso \DP A \to \iso\Phi B \to \DP B \to \DP C
%% \end{align*}

\noindent
Along with the original program's variables, $\phi e$ requires zero change
variables $\dvar\dx$ for every discrete source variable $\dvar x$. Meanwhile,
$\delta e$ requires changes for \emph{every} source program variable (for
discrete variables these will be zero changes), and moreover is \emph{discrete}
with respect to the source program variables (the ``base points'').

We now have enough information to tackle the definitions of $\phi$ and $\delta$
given in \cref{fig:phi,fig:delta}. In the remainder of this section, we'll
examine the most interesting and important parts of these definitions in detail.

\input{fig-phi-delta}


\subsection{Fixed points}

The whole purpose of $\phi$ and $\delta$ is to speed up fixed points, so let's
start there.
%
In a fixed point expression $\efix e$, we know $e : \iso(\fixt L
\to \fixt L)$. Consequently the type of $\phi e$ is

\begin{align*}
  \Phi(\iso(\fixt L \to \fixt L))
  &= \iso(\Phi(\fixt L \to \fixt L) \x \DP(\fixt L \to \fixt L))\\
  &= \iso((\Phi\fixt L \to \Phi\fixt L)
  \x (\iso\Phi \fixt L \to \DP \fixt L \to \DP \fixt L))
  \\
  &= \iso((\fixt L \to \fixt L) \x (\iso\fixt L \to \D \fixt L \to \D\fixt L)
  & \text{by \cref{thm:phi-eqt}, }\Phi\fixt L = \fixt L
  \\
  &= \iso((\fixt L \to \fixt L) \x (\iso\fixt L \to \fixt L \to \fixt L)
  & \text{by \cref{lem:DeltaL}, }\Delta \fixt L = \fixt L
\end{align*}

\noindent
The behavior of $\phi e$ is to compute a boxed pair $\eboxraw{\etuple{f,f'}}$,
where $f : \fixt L \to \fixt L$ is a sped-up function and $f' : \iso\fixt L \to
\fixt L \to \fixt L$ is its derivative. This is exactly what we need to call
\fastfix. Therefore $\phi(\efix e) = \fastfix\<\phi e$.
%
However, if we're going to use $\fastfix$ in the output of $\phi$, we ought to
give it a typing rule and semantics:

\begin{align*}
  \infer{
    \J{e}{\G}{\iso((\fixt L \to \fixt L) \x (\iso\fixt L \to \fixt L \to \fixt L)}
  }{\J{\fastfix\<e}{\G}{\fixt L}}
  &&
  \begin{aligned}
    \den{\fastfix\<e}\<\g &= \fastfix \<(f, f')
    \\
    \text{where}~ & (f,f') = \den{e}\<\g
  \end{aligned}
\end{align*}

As for $\delta(\efix e)$, since $e$ can't change (having $\iso$ type), neither
can $\efix e$ (or $\fastfix\<\phi e$). All we need is a zero change at type
$\fixt L$; by \cref{lem:DeltaL}, $\bot$ suffices.


\subsection{Variables, \boldfn, and application}
\label{sec:var-fn-app}

At the core of a functional language are variables, \fn, and application. The
$\phi$ translation leaves these alone, simply distributing over subexpressions.
On variables, $\delta$ yields the corresponding change variables. On functions
and application, $\delta$ is more interesting:

\begin{align*}
  \DP(A \to B) &= \iso\Phi A \to \DP A \to \DP B
  &
  \delta(\fnof x e) &= \fnof{\eboxvar x} \fnof\dx \delta e
  &
  \delta(e\<f) &= \delta e \<\ebox{\hilite{\phi f}} \<\delta f
\end{align*}

The intuition behind $\delta(\fnof x e) = \fnof{\eboxvar x} \fnof\dx \delta e$
is that a function change takes two arguments, a base point $\dvar x$ and a
change $\dx$, and yields the change in the result of the function, $\delta e$.
However, we are given an argument of type $\iso \Phi A$, but consulting
\cref{thm:type-correct} for the type of $\delta e$, we need a discrete variable
$\hd x {\Phi A}$, so we use pattern-matching to unbox our argument.

The intuition behind $\delta(e\<f) = \delta e \<\ebox{\phi f} \<\delta f$ is
much the same: $\delta e$ needs two arguments, the original input $\phi f$ and
its change $\delta f$, to return the change in the function's output. Moreover,
it's discrete in its first argument, so we need to box it, $\ebox{\phi f}$.

One might wonder why this type-checks, since $\phi e$ and $\delta e$ don't use
the same typing context.
%
We're even boxing $\phi f$, hiding all monotone variables; consequently, it gets
the context $\stripcxraw{\iso\Phi\G, \DP\G}$.
%
However, $\iso$ makes every variable discrete, and $\stripcxraw{-}$ leaves
discrete variables alone, so this includes \emph{at least} $\iso\Phi\G$. The
context $\phi f$ needs is $\Phi\G$. Since $\iso$ only makes a context stronger,
we're safe.
%
The same argument applies (all the more easily) when $\phi e$ is used in a
monotone rather than a discrete position.
%
\todo{Simplify this explanation? We're basically establishing that $\Phi\G
  \sqsubseteq \stripcxraw{\iso\Phi\G, \DP\G}$.}

%% TODO: Discuss self-maintainable functions, citing \citet{incremental}.


\subsection{The discreteness comonad, \iso}
\label{sec:phi-delta-box}

Our strategy hinges on decorating expressions of type $\iso A$ with their
zero-changes, so the translations of $\ebox e$ and $(\eletbox x e f)$ are of
particular interest.
%
The most trivial of these is $\delta\ebox{e} = \etuple{}$; this follows from
$\DP\iso A = \tunit$, since boxed values cannot change.

Next, consider \(\phi\ebox e = \ebox{\etuple{\phi e, \delta e}}\).
%
The intuition here is straightforward: $\phi$ needs to decorate $\isocolor e$
with its zero change; since $\isocolor e$ is discrete and cannot change, we use
$\delta \isocolor e$.
%
However! In general, one cannot use $\delta$ inside the $\phi$ translation and
expect the result to be well-typed; $\phi$ and $\delta$ require different typing
contexts. To see this, let's apply \cref{thm:type-correct} to singleton
contexts:

\begin{center}
  \setlength\tabcolsep{10pt}
  \begin{tabular}{@{}lll@{}}
    $\G$ & $\Phi\G$ & $\iso\Phi\G,\DP\G$
    \\
    %% $e$'s context & $\phi e$'s context & $\delta e$'s context
    %% \\
    \midrule
    $\h x A$ & $\h x {\Phi A}$ & $\hd x {\Phi A}, \h\dx{\DP A}$
    \\
    $\hd x A$
    & $\hd x {\Phi A}, \hd\dx{\DP A}$
    & $\hd x {\Phi A}, \hd\dx{\DP A}$
  \end{tabular}
\end{center}

\noindent
Luckily, although $\Phi\G$ and $\iso\Phi\G,\DP\G$ differ on monotone variables,
they agree on discrete variables. And since $\isocolor e$ is discrete, there
\emph{are} no monotone variables in $\isocolor e$, justifying the use of
$\delta\isocolor e$ in $\phi\ebox{e} = \ebox{\etuple{\phi e, \delta e}}$.

Next we come to $(\eletbox x e f)$, whose $\phi$ and $\delta$ translations are
very similar:

\begin{align*}
  \phi(\eletbox x e f)
  &=
  \elet{\ebox{\etuple{\dvar x,\dvar\dx}} = \phi e} \phi f
  \\
  \delta(\eletbox x e f) &=
  \elet{\ebox{\etuple{\dvar x,\dvar\dx}} = \phi e} \delta f
\end{align*}

\noindent
Since $\dvar x$ is a discrete variable, both $\phi f$ and $\delta f$ need access
to its zero change $\dvar\dx$. Luckily, $\phi e : \iso(\Phi A \x \DP A)$
provides it, so we simply unpack it. We don't use $\delta e$ in $\delta f$, but
this is unsurprising when you consider that its type is $\DP\iso A = \tunit$.


\subsection{Case analysis, \prim{split}, and \name{dummy}}

\newcommand\evalsto\mapsto

The derivative of case-analysis, $\delta(\ecase{e}{(\inj i x_i \caseto
  f_i)_i})$, is complex.
%
Suppose $\phi e$ evaluates to $\inj i x$ and its change $\delta e$ evaluates to
$\inj j \dx$.
%
Since $\delta e$ is a change to $\phi e$, the change structure on sums tells us
that $i = j$! (This is because sums are ordered disjointly; the value $x$ can
increase, but the tag $\injc_i$ must remain the same.)
%
So the desired change $\delta(\ecase{e}{\dots})$ is given by $\delta f_i$ in a
context supplying a discrete base point $\dvar x$ (the value $x$) and the change
$\dx$.
%
To bind $\dvar x$ discretely, we need to use $\ebox{\phi e} : \iso(\Phi A + \Phi
B)$; to pattern-match on this, we need \emph{split} to distribute the $\iso$.

This handles the first two cases, $(\inj i {\eboxvar x},\, \inj i \dx \caseto
\delta f_i)_i$. Since we know the tags on $\phi e$ and $\delta e$ agree, these
are the only possible cases. However, to appease our type-checker we must handle
the \emph{impossible} case that $i \ne j$. This case is dead code: it needs to
typecheck, but is otherwise irrelevant. It suffices to generate a dummy change
$\dx : \DP A_i$ from our base point $\dvar x : \Phi A_i$. We do this using a
simple function $\dummy_A : A \to \D A$ (\cref{fig:dummy}).

\input{fig-dummy}

%% TODO: explain that \phi,\delta(\esplit e) are effectively book-keeping the
%% decorations that the \phi translation adds to \iso.

We also need \dummy\ in the definition of $\phi(\esplit e)$. In effect
$\prim{split} : \iso(A + B) \to \iso A + \iso B$. Observe that

\begin{align*}
  \Phi(\iso (A + B)) &= \iso((\Phi A + \Phi B) \x (\DP A + \DP B))
  \\
  \Phi(\iso A + \iso B) &= \iso(\Phi A \x \DP A) + \iso(\Phi B \x \DP B)
\end{align*}

\noindent
So while $\phi e$ yields a boxed pair of tagged values, $\eboxraw{\etuple{\inj i
    x, \inj j \dx}}$, we need $\phi(\esplit e)$ to yield a tagged boxed pair,
$\inj i {\eboxraw{\etuple{x,\dx}}}$. Again we use \dummy\ to handle the
impossible case $i \ne j$.

Finally, observe that $\delta(\esplit e)$ has type
%
\(
  \DP(\iso A + \iso B)
  = \DP\iso A + \DP\iso B
  = \tunit + \tunit
\).
%
\noindent
All it must do is return $(\inj i \etuple{})$ with a tag that matches
$\phi(\esplit e)$ and $\phi e$; \kw{case}-analysing $\phi e$ suffices.


\subsection{Semilattices and comprehensions}
\label{sec:semilattice-delta-phi}

The translation $\phi(e \vee f) = \phi e \vee \phi f$ is as simple as it seems.
However, $\delta(e \vee f) = \delta e \vee \delta f$ is slightly cleverer. In
particular, let's restrict to sets, and suppose that $\dx$ changes $x$ into $x'$
and $\dy$ changes $y$ to $y'$. In particular, let's suppose these changes are
\emph{precise}: that $\dx = x' \setminus x$ and $\dy = y' \setminus y$. Then
the precise change from $x \cup y$ into $x' \cup y'$ is:

\[ (x' \cup y') \setminus (x \cup y)
= (x' \setminus x \setminus y) \cup (y' \setminus y \setminus x)
= (\dx \setminus y) \cup (\dy \setminus x)
\]

\noindent
This suggests letting $\delta(e \cup f) = (\delta e \setminus \phi f) \cup
(\delta f \setminus \phi e)$. This is a valid derivative, but it involves
recomputing $\phi e$ and $\phi f$, and our goal is to avoid recomputation. So
instead, we \emph{overapproximate} the derivative: $\delta e \cup \delta f$
might contain some unnecessary elements, but we expect it to be cheaper to
include these than to recompute $\phi e$ and $\phi f$. This overapproximation
agrees with semi\naive\ evaluation in Datalog: Datalog implicitly unions the
results of different rules for the same predicate (e.g. those for \name{path} in
\cref{sec:seminaive-and-ilc}), and the semi\naive\ translations of these rules
do not include negated premises to compute a more precise difference.

Now let's consider $\efor x e f$.
%
Its $\phi$-translation is straightforward, with one hitch: because $\hd x {\eqt
  A}$ is a discrete variable, the inner loop $\phi f$ needs access to its zero
change $\hd \dx {\D\eqt A}$.
%
And at eqtypes (although not in general), the \dummy\ function computes zero
changes:
%% TODO: explain why this can't work at function types, which is one reason we
%% restrict sets to containing first-order data?

\begin{lemma}
  $\changesat{\eqt A}{\dummy\<x}{x}{x}$ for any $x : \eqt A$.
\end{lemma}

\noindent For clarity, we write \zero\ rather than \dummy\ when we use it to
produce zero changes; we only call it \dummy\ in dead code.

Finally, we come to $\delta(\efor x e f)$, the computational heart of the
semi\naive\ transformation, as \kw{for} is what enables embedding relational
algebra (the right-hand-sides of Datalog clauses) into Datafun.
%
Here there are two things to consider, corresponding to the two \kw{for}-clauses
$\delta(\efor x e f)$ generates.
%
First, if the set $\phi e$ we're looping over gains new elements $\dvar x \in
\delta e$, we need to compute $\phi f$ over these new elements. Second, if the
inner loop $\phi f$ changes, we need to add in its changes $\delta f$ for every
element, new or old, in the looped-over set, $\phi e \vee \delta e$. Just as in
the $\phi$-translation, we use \zero/\dummy\ to calculate zero-changes to set
elements.


\subsection{Leftovers}

The $\phi$ rules we haven't yet discussed simply distribute $\phi$ over
subexpressions. The remaining $\delta$ rules mostly do the same, with a few
exceptions. In the case of $\delta(\eset{e_i}_i) = \delta(\eeq e f) = \bot$, the
sub-expressions are discrete and cannot change, so we produce a zero-change
$\bot$. This is also the case for $\delta(\eisempty e) = \eisempty{\phi e}$, but
as with $\delta(\esplit e)$, the zero-change here is at type $\tunit + \tunit$,
so to get the tag right we use $\phi e$.
