\section{Introduction}
\label{sec:intro}

Datalog~\cite{datalog}, along with the $\pi$-calculus and \fn-calculus, is one
of the jewel languages of theoretical computer science, connecting programming
language theory, database theory, and complexity theory. In terms of programming
languages, Datalog can be understood as a fully declarative subset of Prolog
which is guaranteed to terminate and so can be evaluated in both top-down and
bottom-up fashion. In terms of database theory, it is equivalent to the
extension of relational algebra with a fixed point operator. In terms of
complexity theory, stratified Datalog over ordered databases characterizes
polytime computation~\cite{datalog-polytime}.

In addition to its theoretical elegance, over the past twenty years
Datalog has seen a surprisingly wide array of uses across a variety of
practical domains, both in research and in industry.
%
Whaley and Lam \cite{whaley-lam,whaley-phd} implemented pointer analysis
algorithms in Datalog, and found that they could reduce their analyses from
thousands of lines of C code to \emph{tens} of lines of Datalog code, while
retaining competitive performance. The DOOP pointer analysis
framework~\cite{doop}, built using the Souffl\'{e} Datalog
engine~\cite{souffle}, shows that this approach can handle almost all of
industrial languages like Java, even analysing features like
reflection~\cite{doop-java-reflection}. Semmle has developed the Datalog-based
.QL language~\cite{semmlecode,ql-inference} for analysing source code (which was
used to analyze the code for NASA's Curiosity Mars rover), and LogicBlox has
developed the LogiQL~\cite{logicblox} language for business analytics and retail
prediction. The Boom project at Berkeley has developed the Bloom language for
distributed programming~\cite{bloom}, and the Datomic cloud
database~\cite{datomic} uses Datalog (embedded in Clojure) as its query
language. Microsoft's SecPAL language~\cite{secpal} uses Datalog as the
foundation of its decentralised authorization specification language. In each
case, when the problem formulated in Datalog, the specification became directly
implementable, while remaining dramatically shorter and clearer than
alternatives implemented in more conventional languages.

% TODO: cite Yannis's recent SNAPL paper ``Next-Paradigm Programming
% Languages: What Will They Look Like and What Changes Will They
% Bring?''

However, there are two flies in the ointment. First, even though each
of these applications is supported by the skeleton of Datalog, they
all had to extend it significantly beyond the theoretical core
calculus.  For example, core Datalog does not even support arithmetic,
since its semantics only speaks of finite sets supporting equality of
their elements. Moreover, arithmetic is not a trivial extension, since
it can greatly complicates the semantics (for example, proving that
termination continues to hold). So despite the fact that kernel
Datalog has a very clean semantics, its metatheory seemingly needs to
be laboriously re-established once again for each extension.

A natural approach to solving this problem is to find a language in which to
write the extensions, which preserves the semantic guarantees that Datalog
offers. Two such proposals are Flix~\cite{flix} and Datafun~\cite{datafun}.
Conveniently for our exposition, these two languages embody two alternative
design strategies.

%% FIXME: this is not up-to-date with Flix's current design. I think
%% it's even not up-to-date with Flix's old design. Old Flix wasn't a
%% functional program building a Datalog program, it's the reverse: a
%% Datalog program that can run functional code in certain places to
%% eg. compute lattice aggregations.
%
%% New Flix has both functional code generating Datalog code, and
%% Datalog code being able to run functional code in certain places.
%% So it seems like it should be _very_ close to Datafun in
%% expressivity. I think Madsen has either a draft or a
%% soon-to-be-published paper on this new design.
%
%% Differences between Flix & Datafun as I see them:
%%
%% - Flix doesn't have monotonicity types.
%
%% - Instead Flix integrates with SMT solvers for lightweight
%%   verification of properties including monotonicity,
%%   distributivity, soundness, completeness, etc. However, mostly
%%   only works for 1st-order stuff.
%
%% - Flix makes it easy to extend language with new semilattice types:
%%   you just write the code for the join operation.
%
%% - In Datafun, Datalog is just a mode of use of functional language.
%%   Flix separates the relational/Datalog and functional
%%   sublanguages.
%
%% - In Flix, the semantics of passing around Datalog code in the
%%   functional language are unclear; talking with Madsen, he seemed
%%   unsure what design choice was best.
%
%% But a summary this^ long belongs in related work, not here.

Flix extends a Datalog-like relational language, generalized to handle arbitrary
semilattices instead of only finite sets, with a functional sublanguage, roughly
comparable to ML or Haskell. The functional side can be used to implement custom
semilattices and data structures which can then be used from the Datalog side.
Flix is aimed at static analysis, where working in a semilattice other than
Datalog's native finite powersets can be highly useful. To this end, Flix
integrates with SMT solvers for lightweight verification of properties such as
monotonicity, soundness, and completeness. However, this SMT-based approach
works best for first-order code, and Flix maintains a pretty clear (if
permeable) separation between its relational and functional sublanguages.

%% Flix adopts the route of treating Datalog as an embedded domain-specific
%% language~\cite{edsl}.
%% %
%% That is, Flix is a fairly conventional (albeit well-designed) functional
%% programming language roughly comparable to ML or Haskell, extended with types
%% representing Datalog predicates and programs.
%% %
%% The evaluation of a Flix program builds a Datalog program, which is then handed
%% off to a custom Datalog engine (albeit extended to support arbitrary
%% semilattices).
%% %
%% This stratification means that (a) standard Datalog implementation techniques
%% can be used mostly off-the-shelf, but that (b) its functional programming side
%% is mostly a very powerful macro system for Datalog.
%% %
%% The only way Flix code runs at Datalog execution time is via the definition of
%% new semilattices (which is functional Flix code implementing a semilattice
%% interface), and for this Flix offers program-verification style correctness
%% checking (including SMT-based tooling).

Datafun, by contrast, is a functional language capable of expressing relational
idioms directly.
%
Datafun's type system tracks \emph{monotonicity} of functions, including
higher-order functions.
%
Datalog-style recursively defined relations are given via an explicit fixed
point operator; monotonicity ensures uniqueness of this fixed point, playing a
role similar to stratification in Datalog.
%
Tracking monotonicity permits a tighter integration between the functional and
relational styles, but it comes at a cost: many of Datalog's standard
implementation techniques, developed in the context of a first-order logic
language, are not obviously applicable in a higher-order functional setting.

Second, making Datalog perform well enough to use in practice calls for very
sophisticated program analysis and compiler engineering. (This is a familiar
experience from the database community, where query planners must encode a
startling amount of knowledge to optimize relatively simple SQL queries.) A wide
variety of techniques for optimizing Datalog programs have been studied in the
literature, such as using binary decision diagrams to represent
relations~\cite{whaley-phd}, exploiting the structure of well-behaved subsets
(e.g., CFL-reachability problems correspond to the ``chain program'' fragment of
Datalog~\cite{chain-programs}), and combining top-down and bottom-up evaluation
via the ``magic sets'' algorithm~\cite{magic-sets}.

Today, one of the workhorse techniques for implementing bottom-up
Datalog engines is \emph{semi\naive\ evaluation}~\cite{seminaive}.
This optimization improves the performance of Datalog's most
distinctive feature: recursively defined predicates. These can be
understood as the fixed point of a set-valued function $f$. The
\naive\ way to compute this is to iterate the sequence $\emptyset,
f(\emptyset), f^2(\emptyset), \dots$ until $f^i(\emptyset) =
f^{i+1}(\emptyset)$. However, each iteration will recompute all
previous values. Semi\naive\ evaluation instead computes a safe
approximation of the \emph{difference} between iterations. This
optimization is critical, as it can asymptotically improve the
performance of Datalog queries.

\paragraph{Contributions} The semi\naive\ evaluation algorithm is
defined partly as a program transformation on sets of Datalog rules,
and partly as a modification of the fixed point computation algorithm.
The central contribution of this paper is to give an extended version
of this transformation which works on higher-order programs written
in the Datafun language.

\begin{itemize}
\item We reformulate Datafun in terms of a kernel calculus based on
  the modal logic S4. Instead of giving a calculus with distinct
  monotonic and discrete function types, as in the original Datafun
  paper, we make discreteness into a comonad. In addition to
  regularizing the calculus and slightly improving its expressiveness,
  the explicit comonadic structure lets us impose a modal constraint
  on recursion reminiscent of Hoffman's work on safe
  recursion~\cite{hofmann-safe-recursion}. This brings the semantics
  of Datafun more closely in line with Datalog's, and substantially
  simplifies the program transformations we present.
  
%% \item We define a program transformation to \emph{incrementalize}
%%   well-typed Datafun programs. The translation is a compositional
%%   type-and-syntax-directed transformation, and works uniformly at all
%%   types including function types. We build on the \emph{change
%%     structure} approach to static program incrementalization
%%   introduced by \citet{incremental}, extending it to support sum
%%   types, set types, comonads, and (well-founded) fixed points.

\item We define two type-and-syntax-directed program transformations on Datafun:
  one to implement semi\naive\ evaluation, and an auxilliary translation that
  incrementalizes programs with respect to increasing changes. We build on the
  \emph{change structure} approach to static program incrementalization
  introduced by \citet{incremental}, extending it to support sum types, set
  types, a comonad, and (well-founded) fixed points.

\item We establish the correctness of these transformations using a novel
  logical relation which captures the relation between the source program, its
  incrementalization, and its semi\naive\ translation. The fundamental lemma
  shows that our transformation is semantics-preserving: any closed program of
  first-order type has the same meaning after optimization.

%% defines the changes connecting
%%   old and updated programs, as well as the optimized version of both.

\item We discuss our implementation of a compiler from Datafun to Haskell, in
  both \naive\ and semi\naive\ form. This lets us empirically demonstrate the
  asymptotic speedups predicted by the theory. We additionally discuss the
  (surprisingly modest) set of auxilliary optimizations we found helpful for
  putting semi\naive\ evaluation into practice.
\end{itemize}
